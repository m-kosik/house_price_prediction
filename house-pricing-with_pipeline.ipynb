{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3722f82",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-19T12:57:00.204107Z",
     "iopub.status.busy": "2021-11-19T12:57:00.203404Z",
     "iopub.status.idle": "2021-11-19T12:57:00.268708Z",
     "shell.execute_reply": "2021-11-19T12:57:00.26804Z",
     "shell.execute_reply.started": "2021-11-19T12:57:00.204062Z"
    },
    "papermill": {
     "duration": 0.013288,
     "end_time": "2021-11-19T23:45:49.115193",
     "exception": false,
     "start_time": "2021-11-19T23:45:49.101905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook is based entirely on the knowledge which I gained from doing the Machine Learning courses on Kaggle and reading sklearn/pandas documentation.  \n",
    "\n",
    "I tried here to create an automated pipeline for feature preparation, which does:\n",
    "- remove numerical columns with a large amount of missing data,\n",
    "- impute missing data in categorical columns and in the numerical columns which have most entries and a small part of missing data,\n",
    "- removes features have small mutual information with the target,\n",
    "- creates new features by applying PCA to numerical features,\n",
    "- performs One Hot Encoding on the categorical data.\n",
    "\n",
    "Next, the preprocessed data is fed into a simple XGBRegressor model, which can be run with early stopping rounds, when performed on the train/validations sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec2e25f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T23:45:49.148426Z",
     "iopub.status.busy": "2021-11-19T23:45:49.147752Z",
     "iopub.status.idle": "2021-11-19T23:45:50.740281Z",
     "shell.execute_reply": "2021-11-19T23:45:50.739467Z",
     "shell.execute_reply.started": "2021-11-19T23:04:40.139957Z"
    },
    "papermill": {
     "duration": 1.612022,
     "end_time": "2021-11-19T23:45:50.740463",
     "exception": false,
     "start_time": "2021-11-19T23:45:49.128441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Read the data\n",
    "X = pd.read_csv('../input/home-data-for-ml-course/train.csv', index_col='Id') \n",
    "X_test = pd.read_csv('../input/home-data-for-ml-course/test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40552ecd",
   "metadata": {
    "papermill": {
     "duration": 0.009904,
     "end_time": "2021-11-19T23:45:50.760859",
     "exception": false,
     "start_time": "2021-11-19T23:45:50.750955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First, analyze general facts about the data (if there are missing values and what types of data occur) and check for outliers using PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "700b7780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T23:45:50.841216Z",
     "iopub.status.busy": "2021-11-19T23:45:50.827905Z",
     "iopub.status.idle": "2021-11-19T23:45:50.846979Z",
     "shell.execute_reply": "2021-11-19T23:45:50.846116Z",
     "shell.execute_reply.started": "2021-11-19T23:04:40.208468Z"
    },
    "papermill": {
     "duration": 0.074012,
     "end_time": "2021-11-19T23:45:50.847216",
     "exception": false,
     "start_time": "2021-11-19T23:45:50.773204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total of 79 features.\n",
      "There are 34 features with missing entries in the training and test set.\n",
      "There are 43 categorical features.\n",
      "There are 36 numerical features.\n"
     ]
    }
   ],
   "source": [
    "print(f'There is a total of {len(X.columns)} features.')\n",
    "\n",
    "cols_with_missing = set([col for col in X.columns if X[col].isnull().any()])\n",
    "cols_with_missing.update([col for col in X_test.columns if X_test[col].isnull().any()])\n",
    "print(f'There are {len(cols_with_missing)} features with missing entries in the training and test set.')\n",
    "\n",
    "cat = (X.dtypes == 'object')\n",
    "categorical_cols = list(cat[cat].index)\n",
    "print(f'There are {len(categorical_cols)} categorical features.')\n",
    "\n",
    "num = (X.dtypes != 'object')\n",
    "num_cols = list(num[num].index)\n",
    "print(f'There are {len(num_cols)} numerical features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3546eb1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T23:45:50.913314Z",
     "iopub.status.busy": "2021-11-19T23:45:50.895629Z",
     "iopub.status.idle": "2021-11-19T23:45:51.271229Z",
     "shell.execute_reply": "2021-11-19T23:45:51.271957Z",
     "shell.execute_reply.started": "2021-11-19T23:04:40.269323Z"
    },
    "papermill": {
     "duration": 0.408322,
     "end_time": "2021-11-19T23:45:51.272180",
     "exception": false,
     "start_time": "2021-11-19T23:45:50.863858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 10 PCA components explain these amounts of variance:\n",
      "[0.19386639 0.09564245 0.06510423 0.05987158 0.04440183 0.03584957\n",
      " 0.03483578 0.03356583 0.03259043 0.03155213]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca_features = [col for col in num_cols if not X[col].isnull().any()]\n",
    "\n",
    "def apply_pca(X, standardize=True):\n",
    "    if standardize:\n",
    "        X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
    "    X_pca = pd.DataFrame(X_pca, columns=component_names)\n",
    "    loadings = pd.DataFrame(\n",
    "        pca.components_.T,  # transpose the matrix of loadings\n",
    "        columns=component_names,  # so the columns are the principal components\n",
    "        index=X.columns,  # and the rows are the original features\n",
    "    )\n",
    "    return pca, X_pca, loadings\n",
    "\n",
    "pca, X_pca, loadings = apply_pca(X[pca_features])\n",
    "\n",
    "print('The first 10 PCA components explain these amounts of variance:')\n",
    "print(pca.explained_variance_ratio_[:10])\n",
    "\n",
    "component_to_see = 'PC1'\n",
    "distribution = X_pca.melt()\n",
    "distribution = distribution.loc[distribution['variable'] == component_to_see]\n",
    "\n",
    "sns.catplot(\n",
    "    y=\"value\",\n",
    "    col=\"variable\",\n",
    "    data=distribution,\n",
    "    kind='boxen',\n",
    "    sharey=False,\n",
    "    col_wrap=2,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8cccca",
   "metadata": {
    "papermill": {
     "duration": 0.012852,
     "end_time": "2021-11-19T23:45:51.298412",
     "exception": false,
     "start_time": "2021-11-19T23:45:51.285560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below, I define the function which will preprocess data. It takes as arguments: \n",
    "- a train set `X` \n",
    "- a test/validation set `X_test` \n",
    "- the target output as `y`.  \n",
    "\n",
    "It works on copies of the `X` and `X_test` data, and returns these two datasets after completing all preprocessing steps, which include:\n",
    "- removing numerical columns which have more than `missing_threshold` missing entries,\n",
    "- imputing missing data in the rest of the numerical columns with missing data using the median value or 0,\n",
    "- imputing missing data in categorical columns with a new value (often the NaN in categorical data has the meaning of a new category, e.g. \"the absence of a garage\") \n",
    "- removing features have mutual information with the target smaller than `mutual_inf_threshold`,\n",
    "- creates new features by applying PCA to existing numerical features and then adding as new features the first `pca_components_to_include` components\n",
    "- dropping categorical data that have cardinality larger than `low_cardinality_threshold`,\n",
    "- performing One Hot Encoding on the low-cardinality categorical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6fa5b99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T23:45:51.356476Z",
     "iopub.status.busy": "2021-11-19T23:45:51.355757Z",
     "iopub.status.idle": "2021-11-19T23:45:51.359337Z",
     "shell.execute_reply": "2021-11-19T23:45:51.358701Z",
     "shell.execute_reply.started": "2021-11-19T23:04:40.600811Z"
    },
    "papermill": {
     "duration": 0.047694,
     "end_time": "2021-11-19T23:45:51.359496",
     "exception": false,
     "start_time": "2021-11-19T23:45:51.311802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "def preprocessing_pipeline(X, y, X_test, \n",
    "                           missing_threshold=100, \n",
    "                           mutual_inf_threshold=0.05, \n",
    "                           low_cardinality_threshold=15,\n",
    "                           pca_components_to_include=10,\n",
    "                           verbose = False):\n",
    "    \n",
    "    data = X.copy()\n",
    "    data_test = X_test.copy()\n",
    "    \n",
    "    if verbose:\n",
    "        print('**************************')\n",
    "        print('\\nNumber of features at the beginning:')\n",
    "        print(len(data.columns))\n",
    "        print(len(data_test.columns))\n",
    "    \n",
    "    #--- Impute missing values\n",
    "    cols_with_missing = set([col for col in data.columns if data[col].isnull().any()])\n",
    "    cols_with_missing.update([col for col in data_test.columns if data_test[col].isnull().any()])\n",
    "    if verbose:\n",
    "        print('Columns with missing values: ')\n",
    "        print(cols_with_missing)\n",
    "    \n",
    "    cols_to_drop = [col for col in cols_with_missing if data[col].isnull().sum()>missing_threshold] \n",
    "    cols_with_missing_num = [col for col in cols_with_missing if data[col].isnull().sum()<missing_threshold and data[col].dtype != \"object\"] \n",
    "    cols_with_missing_cat = [col for col in cols_with_missing if data[col].isnull().sum()<missing_threshold and data[col].dtype == \"object\"]\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\n Columns which will be dropped due to a lot of missing values: ')\n",
    "        print(cols_to_drop)\n",
    "    data = data.drop(cols_to_drop, axis=1)\n",
    "    data_test = data_test.drop(cols_to_drop, axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\nNumber of features after dropping missing values:')\n",
    "        print(len(data.columns))\n",
    "        print(len(data_test.columns))\n",
    "    \n",
    "    for column in cols_with_missing_num:\n",
    "        if column == 'LotFrontage':\n",
    "            data[column] = data[column].fillna(data[column].median())\n",
    "            data_test[column] = data_test[column].fillna(data_test[column].median())\n",
    "        else:\n",
    "            data[column] = data[column].fillna(0)\n",
    "            data_test[column] = data_test[column].fillna(0)\n",
    "    \n",
    "    for column in cols_with_missing_cat:\n",
    "        data[column] = data[column].fillna('N')\n",
    "        data_test[column] = data_test[column].fillna('N')\n",
    "    \n",
    "    imputed = data.copy()\n",
    "    imputed_test = data_test.copy()\n",
    "\n",
    "    imputed.columns = data.columns\n",
    "    imputed_test.columns = data_test.columns\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\nNumber of features after imputation:')\n",
    "        print(len(imputed.columns))\n",
    "        print(len(imputed_test.columns))\n",
    "    \n",
    "    #--- Throw away numerical features which have very small mutual information with target\n",
    "    num = (data.dtypes != 'object')\n",
    "    num_cols = list(num[num].index)\n",
    "    \n",
    "    mi_scores = make_mi_scores(imputed[num_cols], y, 'auto')\n",
    "    if verbose:\n",
    "        print('\\nNumerical features with highest mutual information with target: ')\n",
    "        print(mi_scores)\n",
    "    \n",
    "    unimportant_columns = [index for index,score in mi_scores.iteritems() if score < mutual_inf_threshold]\n",
    "    if verbose:\n",
    "        print('\\nColumns which will be dropped: ')\n",
    "        print(unimportant_columns)\n",
    "    \n",
    "    high_mi = imputed.drop(unimportant_columns, axis=1)\n",
    "    high_mi_test = imputed_test.drop(unimportant_columns, axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\nNumber of features after dropping low MI features:')\n",
    "        print(len(high_mi.columns))\n",
    "        print(len(high_mi_test.columns))\n",
    "    \n",
    "    #--- Apply PCA to numerical features\n",
    "    important_num_columns = list(set(num_cols) - set(unimportant_columns))\n",
    "    pca, X_pca, loadings = apply_pca(high_mi[important_num_columns], standardize=False)\n",
    "    pca_test, X_pca_test, loadings_test = apply_pca(high_mi_test[important_num_columns],standardize=False)\n",
    "\n",
    "    first_n_components = [f\"PC{i+1}\" for i in range(pca_components_to_include)]\n",
    "    data_after_pca = high_mi.join(X_pca[first_n_components])\n",
    "    data_after_pca_test = high_mi_test.join(X_pca_test[first_n_components])\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nNumber of features after adding PCA components:')\n",
    "        print(len(data_after_pca.columns))\n",
    "        print(len(data_after_pca_test.columns))\n",
    "        \n",
    "    #--- Encode categorical features\n",
    "    \n",
    "    cat = (high_mi.dtypes == 'object')\n",
    "    categorical_cols = list(cat[cat].index)\n",
    "    low_cardinality_cols = [col for col in categorical_cols if data_after_pca[col].nunique() < low_cardinality_threshold]\n",
    "    high_cardinality_cols = list(set(categorical_cols)-set(low_cardinality_cols))\n",
    "    \n",
    "    lc_X_train = data_after_pca.drop(high_cardinality_cols, axis=1)\n",
    "    lc_X_valid = data_after_pca_test.drop(high_cardinality_cols, axis=1)\n",
    "    \n",
    "    OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(lc_X_train[low_cardinality_cols]))\n",
    "    OH_cols_valid = pd.DataFrame(OH_encoder.transform(lc_X_valid[low_cardinality_cols]))\n",
    "    \n",
    "    OH_cols_train.index = data_after_pca.index\n",
    "    OH_cols_valid.index = data_after_pca_test.index\n",
    "    num_X_train = data_after_pca.drop(categorical_cols, axis=1)\n",
    "    num_X_valid = data_after_pca_test.drop(categorical_cols, axis=1)\n",
    "    OH_X = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "    OH_X_test = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\nNumber of features after OHE:')\n",
    "        print(len(OH_X.columns)) \n",
    "        print(len(OH_X_test.columns))\n",
    "    \n",
    "    return OH_X, OH_X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca7eef6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T18:58:54.38704Z",
     "iopub.status.busy": "2021-11-19T18:58:54.386219Z",
     "iopub.status.idle": "2021-11-19T18:58:54.414167Z",
     "shell.execute_reply": "2021-11-19T18:58:54.413283Z",
     "shell.execute_reply.started": "2021-11-19T18:58:54.38693Z"
    },
    "papermill": {
     "duration": 0.011641,
     "end_time": "2021-11-19T23:45:51.383277",
     "exception": false,
     "start_time": "2021-11-19T23:45:51.371636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, four loops are run to find the optimal values of the hyperparameters of the preprocessing pipeline. \n",
    "Note that XGBRegressor is run with early stopping rounds to speed up the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f34d356",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T23:45:51.418862Z",
     "iopub.status.busy": "2021-11-19T23:45:51.418166Z",
     "iopub.status.idle": "2021-11-19T23:55:01.884339Z",
     "shell.execute_reply": "2021-11-19T23:55:01.884877Z",
     "shell.execute_reply.started": "2021-11-19T23:04:40.635541Z"
    },
    "papermill": {
     "duration": 550.48973,
     "end_time": "2021-11-19T23:55:01.885085",
     "exception": false,
     "start_time": "2021-11-19T23:45:51.395355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: 100, 0, 10, 0\n",
      "**********************************************\n",
      "100\n",
      "0\n",
      "10\n",
      "16601.47709760274\n",
      "running: 100, 0, 10, 10\n",
      "**********************************************\n",
      "100\n",
      "0\n",
      "10\n",
      "17022.426102311645\n",
      "running: 100, 0, 30, 0\n",
      "**********************************************\n",
      "100\n",
      "0\n",
      "30\n",
      "16085.441152076199\n",
      "running: 100, 0, 30, 10\n",
      "**********************************************\n",
      "100\n",
      "0\n",
      "30\n",
      "16514.491331335616\n",
      "running: 100, 0, 40, 0\n",
      "**********************************************\n",
      "100\n",
      "0\n",
      "40\n",
      "16085.441152076199\n",
      "running: 100, 0, 40, 10\n",
      "**********************************************\n",
      "100\n",
      "0\n",
      "40\n",
      "16514.491331335616\n",
      "running: 100, 0.05, 10, 0\n",
      "**********************************************\n",
      "100\n",
      "0.05\n",
      "10\n",
      "16647.255377782534\n",
      "running: 100, 0.05, 10, 10\n",
      "**********************************************\n",
      "100\n",
      "0.05\n",
      "10\n",
      "16491.619715860445\n",
      "running: 100, 0.05, 30, 0\n",
      "**********************************************\n",
      "100\n",
      "0.05\n",
      "30\n",
      "16200.106900149829\n",
      "running: 100, 0.05, 30, 10\n",
      "**********************************************\n",
      "100\n",
      "0.05\n",
      "30\n",
      "15929.171326519692\n",
      "running: 100, 0.05, 40, 0\n",
      "**********************************************\n",
      "100\n",
      "0.05\n",
      "40\n",
      "16200.106900149829\n",
      "running: 100, 0.05, 40, 10\n",
      "**********************************************\n",
      "100\n",
      "0.05\n",
      "40\n",
      "16339.270133240581\n",
      "running: 100, 0.1, 10, 0\n",
      "**********************************************\n",
      "100\n",
      "0.1\n",
      "10\n",
      "16557.489578874145\n",
      "running: 100, 0.1, 10, 10\n",
      "**********************************************\n",
      "100\n",
      "0.1\n",
      "10\n",
      "16625.248354559077\n",
      "running: 100, 0.1, 30, 0\n",
      "**********************************************\n",
      "100\n",
      "0.1\n",
      "30\n",
      "16604.162323416094\n",
      "running: 100, 0.1, 30, 10\n",
      "**********************************************\n",
      "100\n",
      "0.1\n",
      "30\n",
      "15821.551396618152\n",
      "running: 100, 0.1, 40, 0\n",
      "**********************************************\n",
      "100\n",
      "0.1\n",
      "40\n",
      "16026.237451840754\n",
      "running: 100, 0.1, 40, 10\n",
      "**********************************************\n",
      "100\n",
      "0.1\n",
      "40\n",
      "16321.683112157534\n",
      "running: 100, 0.15, 10, 0\n",
      "**********************************************\n",
      "100\n",
      "0.15\n",
      "10\n",
      "16527.825690282534\n",
      "running: 100, 0.15, 10, 10\n",
      "**********************************************\n",
      "100\n",
      "0.15\n",
      "10\n",
      "17154.046313142124\n",
      "running: 100, 0.15, 30, 0\n",
      "**********************************************\n",
      "100\n",
      "0.15\n",
      "30\n",
      "16064.81108197774\n",
      "running: 100, 0.15, 30, 10\n",
      "**********************************************\n",
      "100\n",
      "0.15\n",
      "30\n",
      "16612.21733197774\n",
      "running: 100, 0.15, 40, 0\n",
      "**********************************************\n",
      "100\n",
      "0.15\n",
      "40\n",
      "16297.029136344177\n",
      "running: 100, 0.15, 40, 10\n",
      "**********************************************\n",
      "100\n",
      "0.15\n",
      "40\n",
      "16612.21733197774\n",
      "running: 500, 0, 10, 0\n",
      "**********************************************\n",
      "500\n",
      "0\n",
      "10\n",
      "16808.707526220034\n",
      "running: 500, 0, 10, 10\n",
      "**********************************************\n",
      "500\n",
      "0\n",
      "10\n",
      "17332.635421125855\n",
      "running: 500, 0, 30, 0\n",
      "**********************************************\n",
      "500\n",
      "0\n",
      "30\n",
      "16384.44080425942\n",
      "running: 500, 0, 30, 10\n",
      "**********************************************\n",
      "500\n",
      "0\n",
      "30\n",
      "16946.276701626713\n",
      "running: 500, 0, 40, 0\n",
      "**********************************************\n",
      "500\n",
      "0\n",
      "40\n",
      "16384.44080425942\n",
      "running: 500, 0, 40, 10\n",
      "**********************************************\n",
      "500\n",
      "0\n",
      "40\n",
      "16946.276701626713\n",
      "running: 500, 0.05, 10, 0\n",
      "**********************************************\n",
      "500\n",
      "0.05\n",
      "10\n",
      "16662.80851348459\n",
      "running: 500, 0.05, 10, 10\n",
      "**********************************************\n",
      "500\n",
      "0.05\n",
      "10\n",
      "16877.66700556507\n",
      "running: 500, 0.05, 30, 0\n",
      "**********************************************\n",
      "500\n",
      "0.05\n",
      "30\n",
      "16242.697961258562\n",
      "running: 500, 0.05, 30, 10\n",
      "**********************************************\n",
      "500\n",
      "0.05\n",
      "30\n",
      "16558.28462114726\n",
      "running: 500, 0.05, 40, 0\n",
      "**********************************************\n",
      "500\n",
      "0.05\n",
      "40\n",
      "16242.697961258562\n",
      "running: 500, 0.05, 40, 10\n",
      "**********************************************\n",
      "500\n",
      "0.05\n",
      "40\n",
      "16558.28462114726\n",
      "running: 500, 0.1, 10, 0\n",
      "**********************************************\n",
      "500\n",
      "0.1\n",
      "10\n",
      "17194.89265839041\n",
      "running: 500, 0.1, 10, 10\n",
      "**********************************************\n",
      "500\n",
      "0.1\n",
      "10\n",
      "16664.090057791094\n",
      "running: 500, 0.1, 30, 0\n",
      "**********************************************\n",
      "500\n",
      "0.1\n",
      "30\n",
      "16462.392069777397\n",
      "running: 500, 0.1, 30, 10\n",
      "**********************************************\n",
      "500\n",
      "0.1\n",
      "30\n",
      "16229.468455693494\n",
      "running: 500, 0.1, 40, 0\n",
      "**********************************************\n",
      "500\n",
      "0.1\n",
      "40\n",
      "16462.392069777397\n",
      "running: 500, 0.1, 40, 10\n",
      "**********************************************\n",
      "500\n",
      "0.1\n",
      "40\n",
      "16549.18466395548\n",
      "running: 500, 0.15, 10, 0\n",
      "**********************************************\n",
      "500\n",
      "0.15\n",
      "10\n",
      "17161.342893835616\n",
      "running: 500, 0.15, 10, 10\n",
      "**********************************************\n",
      "500\n",
      "0.15\n",
      "10\n",
      "17723.982528895547\n",
      "running: 500, 0.15, 30, 0\n",
      "**********************************************\n",
      "500\n",
      "0.15\n",
      "30\n",
      "16687.205747003423\n",
      "running: 500, 0.15, 30, 10\n",
      "**********************************************\n",
      "500\n",
      "0.15\n",
      "30\n",
      "17136.567690496577\n",
      "running: 500, 0.15, 40, 0\n",
      "**********************************************\n",
      "500\n",
      "0.15\n",
      "40\n",
      "16950.35172303082\n",
      "running: 500, 0.15, 40, 10\n",
      "**********************************************\n",
      "500\n",
      "0.15\n",
      "40\n",
      "17136.567690496577\n",
      "running: 1000, 0, 10, 0\n",
      "**********************************************\n",
      "1000\n",
      "0\n",
      "10\n",
      "16725.399226776542\n",
      "running: 1000, 0, 10, 10\n",
      "**********************************************\n",
      "1000\n",
      "0\n",
      "10\n",
      "17385.25256849315\n",
      "running: 1000, 0, 30, 0\n",
      "**********************************************\n",
      "1000\n",
      "0\n",
      "30\n",
      "16267.971037564212\n",
      "running: 1000, 0, 30, 10\n",
      "**********************************************\n",
      "1000\n",
      "0\n",
      "30\n",
      "16797.290346746577\n",
      "running: 1000, 0, 40, 0\n",
      "**********************************************\n",
      "1000\n",
      "0\n",
      "40\n",
      "16267.971037564212\n",
      "running: 1000, 0, 40, 10\n",
      "**********************************************\n",
      "1000\n",
      "0\n",
      "40\n",
      "16797.290346746577\n",
      "running: 1000, 0.05, 10, 0\n",
      "**********************************************\n",
      "1000\n",
      "0.05\n",
      "10\n",
      "16763.938543450342\n",
      "running: 1000, 0.05, 10, 10\n",
      "**********************************************\n",
      "1000\n",
      "0.05\n",
      "10\n",
      "16968.96583369007\n",
      "running: 1000, 0.05, 30, 0\n",
      "**********************************************\n",
      "1000\n",
      "0.05\n",
      "30\n",
      "16145.36053884846\n",
      "running: 1000, 0.05, 30, 10\n",
      "**********************************************\n",
      "1000\n",
      "0.05\n",
      "30\n",
      "16603.47875642123\n",
      "running: 1000, 0.05, 40, 0\n",
      "**********************************************\n",
      "1000\n",
      "0.05\n",
      "40\n",
      "16145.36053884846\n",
      "running: 1000, 0.05, 40, 10\n",
      "**********************************************\n",
      "1000\n",
      "0.05\n",
      "40\n",
      "16603.47875642123\n",
      "running: 1000, 0.1, 10, 0\n",
      "**********************************************\n",
      "1000\n",
      "0.1\n",
      "10\n",
      "17134.13243792808\n",
      "running: 1000, 0.1, 10, 10\n",
      "**********************************************\n",
      "1000\n",
      "0.1\n",
      "10\n",
      "17554.095596104453\n",
      "running: 1000, 0.1, 30, 0\n",
      "**********************************************\n",
      "1000\n",
      "0.1\n",
      "30\n",
      "16334.811122110445\n",
      "running: 1000, 0.1, 30, 10\n",
      "**********************************************\n",
      "1000\n",
      "0.1\n",
      "30\n",
      "16285.036467251712\n",
      "running: 1000, 0.1, 40, 0\n",
      "**********************************************\n",
      "1000\n",
      "0.1\n",
      "40\n",
      "16866.66671125856\n",
      "running: 1000, 0.1, 40, 10\n",
      "**********************************************\n",
      "1000\n",
      "0.1\n",
      "40\n",
      "16285.036467251712\n",
      "running: 1000, 0.15, 10, 0\n",
      "**********************************************\n",
      "1000\n",
      "0.15\n",
      "10\n",
      "17263.32138270548\n",
      "running: 1000, 0.15, 10, 10\n",
      "**********************************************\n",
      "1000\n",
      "0.15\n",
      "10\n",
      "17513.32927547089\n",
      "running: 1000, 0.15, 30, 0\n",
      "**********************************************\n",
      "1000\n",
      "0.15\n",
      "30\n",
      "16760.642096532534\n",
      "running: 1000, 0.15, 30, 10\n",
      "**********************************************\n",
      "1000\n",
      "0.15\n",
      "30\n",
      "16926.300379922945\n",
      "running: 1000, 0.15, 40, 0\n",
      "**********************************************\n",
      "1000\n",
      "0.15\n",
      "40\n",
      "16667.910905393837\n",
      "running: 1000, 0.15, 40, 10\n",
      "**********************************************\n",
      "1000\n",
      "0.15\n",
      "40\n",
      "16908.381581763697\n",
      "15821.551396618152\n",
      "(100, 0.1, 30, 10)\n"
     ]
    }
   ],
   "source": [
    "smallest_mae = 30_000\n",
    "\n",
    "for missing_threshold in [100, 500, 1000]:\n",
    "    for mutual_inf_threshold in [0, 0.05, 0.1, 0.15]:\n",
    "        for low_cardinality_threshold in [10, 30, 40]:\n",
    "            for pca_components_to_include in [0, 10]:\n",
    "                print(f'running: {missing_threshold}, {mutual_inf_threshold}, {low_cardinality_threshold}, {pca_components_to_include}')\n",
    "\n",
    "                processed_X_train, processed_X_valid = preprocessing_pipeline(X_train, y_train, X_valid, \n",
    "                                                                              missing_threshold=missing_threshold,      \n",
    "                                                                              mutual_inf_threshold=mutual_inf_threshold, \n",
    "                                                                              low_cardinality_threshold=low_cardinality_threshold,\n",
    "                                                                              pca_components_to_include=pca_components_to_include)\n",
    "                \n",
    "                model = XGBRegressor(n_estimators=5_000, learning_rate = 0.02)\n",
    "                model.fit(processed_X_train, y_train, early_stopping_rounds=10, \n",
    "                          eval_set=[(processed_X_valid, y_valid)],verbose=False)\n",
    "                preds_test = model.predict(processed_X_valid)\n",
    "\n",
    "                print('**********************************************')\n",
    "                print(missing_threshold)\n",
    "                print(mutual_inf_threshold)\n",
    "                print(low_cardinality_threshold)\n",
    "                mae = mean_absolute_error(y_valid, preds_test)\n",
    "                print(mae)\n",
    "                if mae < smallest_mae:\n",
    "                    smallest_mae = mae\n",
    "                    best_params = missing_threshold, mutual_inf_threshold, low_cardinality_threshold, pca_components_to_include\n",
    "\n",
    "print(smallest_mae)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1809fe38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T23:55:01.962638Z",
     "iopub.status.busy": "2021-11-19T23:55:01.961994Z",
     "iopub.status.idle": "2021-11-19T23:56:03.523657Z",
     "shell.execute_reply": "2021-11-19T23:56:03.523011Z",
     "shell.execute_reply.started": "2021-11-19T23:22:53.012290Z"
    },
    "papermill": {
     "duration": 61.602675,
     "end_time": "2021-11-19T23:56:03.523833",
     "exception": false,
     "start_time": "2021-11-19T23:55:01.921158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270 270\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "processed_X_train, processed_X_valid = preprocessing_pipeline(X_train, y_train, X_valid, \n",
    "                                                       missing_threshold=best_params[0],      \n",
    "                                                       mutual_inf_threshold=best_params[1],\n",
    "                                                       low_cardinality_threshold=best_params[2],\n",
    "                                                       pca_components_to_include=best_params[3])\n",
    "print(len(processed_X_train.columns), len(processed_X_valid.columns))\n",
    "\n",
    "model = XGBRegressor(n_estimators = 5_000, learning_rate = 0.02)\n",
    "model.fit(processed_X_train, y_train)\n",
    "preds_test = model.predict(processed_X_valid)\n",
    "mae = mean_absolute_error(y_valid, preds_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86c97da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T19:27:54.652735Z",
     "iopub.status.busy": "2021-11-19T19:27:54.651732Z",
     "iopub.status.idle": "2021-11-19T19:27:54.659187Z",
     "shell.execute_reply": "2021-11-19T19:27:54.658127Z",
     "shell.execute_reply.started": "2021-11-19T19:27:54.652669Z"
    },
    "papermill": {
     "duration": 0.033154,
     "end_time": "2021-11-19T23:56:03.592596",
     "exception": false,
     "start_time": "2021-11-19T23:56:03.559442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, the best parameters will be used to the generate predictions on the entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8023c71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T23:56:03.667806Z",
     "iopub.status.busy": "2021-11-19T23:56:03.667198Z",
     "iopub.status.idle": "2021-11-19T23:57:20.254883Z",
     "shell.execute_reply": "2021-11-19T23:57:20.255372Z",
     "shell.execute_reply.started": "2021-11-19T23:23:46.255169Z"
    },
    "papermill": {
     "duration": 76.629151,
     "end_time": "2021-11-19T23:57:20.255546",
     "exception": false,
     "start_time": "2021-11-19T23:56:03.626395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275 275\n",
      "output saved\n"
     ]
    }
   ],
   "source": [
    "processed_X, processed_X_test = preprocessing_pipeline(X, y, X_test, \n",
    "                                                       missing_threshold=best_params[0],      \n",
    "                                                       mutual_inf_threshold=best_params[1],\n",
    "                                                       low_cardinality_threshold=best_params[2])\n",
    "print(len(processed_X.columns), len(processed_X_test.columns))\n",
    "\n",
    "model = XGBRegressor(n_estimators = 5_000, learning_rate = 0.02)\n",
    "model.fit(processed_X, y)\n",
    "preds_test = model.predict(processed_X_test)\n",
    "\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print('output saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233b7784",
   "metadata": {
    "papermill": {
     "duration": 0.035709,
     "end_time": "2021-11-19T23:57:20.325980",
     "exception": false,
     "start_time": "2021-11-19T23:57:20.290271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The last thing which remains would be optimize the XGBRegressor parameters, e.g. using GridSearchCV."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 700.838904,
   "end_time": "2021-11-19T23:57:21.074114",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-19T23:45:40.235210",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
